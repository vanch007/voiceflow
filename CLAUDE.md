# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

VoiceFlow is a macOS menu bar app for voice-to-text transcription. It captures audio via AVCaptureSession, sends it to a local WebSocket ASR server (Qwen3-ASR on MLX), and injects transcription results into the active application.

**Key Features:**
- Option key long-press or Control double-tap to start/stop recording
- Real-time audio capture with 16kHz resampling
- MLX-accelerated Qwen3-ASR for Apple Silicon
- WebSocket connection to local ASR server with auto-reconnect
- Text polish feature with AI enhancement
- Plugin system for extensible post-ASR processing

## Build & Run

```bash
# Quick start (build + run with logs)
./run.sh

# Build only using xcodebuild
cd VoiceFlow && xcodebuild -scheme VoiceFlow -configuration Debug build

# Open in Xcode for development
open VoiceFlow/VoiceFlow.xcodeproj

# Python environment setup (first time)
scripts/setup.sh

# Build and bundle app
scripts/build.sh

# Start ASR server only
scripts/start-server.sh
```

**Requirements:**
- macOS 14.0+ (Sonoma)
- Xcode 16+ with Command Line Tools
- Python 3.11+
- Accessibility permissions (for global hotkey monitoring)
- Microphone permissions (for audio recording)

## Testing

```bash
# Python server tests
cd server && pytest tests/

# Swift tests (via Xcode)
cd VoiceFlow && xcodebuild test -scheme VoiceFlow -destination 'platform=macOS'
```

## Architecture

### Swift App (`VoiceFlow/Sources/`)

**App Layer** (`App/`)
- `VoiceFlowApp.swift`: SwiftUI app entry point
- `AppDelegate.swift`: Coordinates all managers, spawns Python ASR server

**Core Services** (`Core/`)
- `HotkeyManager.swift`: Global hotkey detection (Option long-press, Control double-tap) via CGEvent tap
- `AudioRecorder.swift`: AVCaptureSession-based audio capture with format conversion
- `ASRClient.swift`: WebSocket client for ASR server communication
- `TextInjector.swift`: CGEvent-based text injection into active apps
- `SettingsManager.swift`: User preferences management
- `ReplacementRule.swift` / `ReplacementStorage.swift`: Text replacement rules
- `LLMSettings.swift`: LLM configuration with Keychain storage for API keys
- `HistoryAnalysisResult.swift`: Recording history analysis result model

**UI Layer** (`UI/`)
- `StatusBarController.swift`: Menu bar item and status management
- `OverlayPanel.swift`: Visual recording indicator (bottom of screen)
- `SettingsWindow.swift`: Settings UI
- `LLMSettingsView.swift`: LLM configuration interface
- `HistoryAnalysisView.swift`: Recording history analysis results display

### Python ASR Server (`server/`)

- `main.py`: WebSocket server (ws://localhost:9876), handles audio streaming and transcription
- `mlx_asr.py`: MLX-based Qwen3-ASR wrapper for Apple Silicon GPU acceleration
- `text_polisher.py`: AI text enhancement using LLM
- `llm_client.py`: OpenAI-compatible LLM client (supports Ollama, vLLM, OpenAI)
- `llm_polisher.py`: LLM-based text polisher with rule fallback
- `history_analyzer.py`: Recording history analysis for keyword extraction

### Plugin System (`Plugins/`)

Extensible post-ASR processing plugins. Each plugin has a `manifest.json` describing its capabilities.
- `ChinesePunctuationPlugin`: Chinese punctuation normalization
- `Examples/`: Sample plugins (PunctuationPlugin, UppercasePlugin)

### Data Flow

```
User long-presses Option key
  â†“
HotkeyManager triggers recording
  â†“
AudioRecorder captures mic input â†’ resamples to 16kHz Float32
  â†“
ASRClient sends audio chunks via WebSocket
  â†“
Python server transcribes with Qwen3-ASR (MLX)
  â†“
Optional: Text polish with LLM + Plugin processing
  â†“
TextInjector pastes text into active app
```

### WebSocket Protocol

**Client â†’ Server:**
- `{"type": "start", "model": "...", "language": "...", "polish": true/false}` - Start session
- `{"type": "stop"}` - End session
- Binary audio data (Float32, 16kHz, mono)

**Server â†’ Client:**
- `{"type": "final", "text": "...", "polish_method": "llm"|"rules"|"none"}` - Final transcription result
- `{"type": "partial", "text": "..."}` - Partial result during recording
- `{"type": "test_llm_connection_result", "success": bool, "latency_ms": int}` - LLM connection test
- `{"type": "analysis_result", "result": {...}}` - History analysis result

**LLM Configuration Messages:**
- `{"type": "config_llm", "config": {...}}` - Configure LLM connection (Client â†’ Server)
- `{"type": "test_llm_connection"}` - Test LLM service availability (Client â†’ Server)
- `{"type": "analyze_history", "entries": [...], "app_name": "..."}` - Analyze recording history (Client â†’ Server)

## Recent Features

### Two-Phase Polish Strategy
æ–‡æœ¬æ¶¦è‰²é‡‡ç”¨ä¸¤é˜¶æ®µå“åº”ç­–ç•¥å‡å°‘æ„ŸçŸ¥å»¶è¿Ÿï¼š
1. ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿè¿”å›åŸºç¡€æ¶¦è‰²ç»“æœ
2. ç¬¬äºŒé˜¶æ®µï¼šé€šè¿‡ `polish_update` æ¶ˆæ¯æ¨é€ LLM å¢å¼ºç»“æœ

ç›¸å…³æ–‡ä»¶ï¼š`ASRClient.swift` (onPolishUpdate)ã€`server/main.py`ã€`TextInjector.swift`

### FreeSpeak Mode
åˆ‡æ¢å¼å½•éŸ³æ¨¡å¼ï¼ˆåŒºåˆ«äºæŒ‰ä½è§¦å‘ï¼‰ï¼Œæ”¯æŒï¼š
- `HotkeyConfig.swift` ä¸­çš„ `freeSpeak` è§¦å‘ç±»å‹
- é™éŸ³æ£€æµ‹è‡ªåŠ¨åœæ­¢å½•éŸ³ï¼ˆ`AudioRecorder.swift` ä¸­çš„ silence detectionï¼‰
- `OverlayPanel` æ˜¾ç¤ºé™éŸ³å€’è®¡æ—¶

### Context-Aware Polishing
æ ¹æ®æ´»è·ƒåº”ç”¨è‡ªåŠ¨é€‰æ‹©æ¶¦è‰²åœºæ™¯ï¼š
- `ASRClient` åœ¨ start æ¶ˆæ¯ä¸­å‘é€ `active_app` ä¸Šä¸‹æ–‡
- `LLMPolisher` æ ¹æ®åº”ç”¨åç§°æ˜ å°„åˆ°å¯¹åº”åœºæ™¯
- `server/main.py` åˆå¹¶åº”ç”¨ä¸Šä¸‹æ–‡åˆ°ä¼šè¯åœºæ™¯

### Scene Profiles (`Core/Scene/`)
- `SceneProfile.swift`: åœºæ™¯é…ç½®æ¨¡å‹
- åœºæ™¯å¯é…ç½®ï¼šè¯­è¨€ï¼ˆæ”¯æŒè·Ÿéšå…¨å±€è®¾ç½®ï¼‰ã€æ¶¦è‰²è§„åˆ™ã€LLM æç¤ºè¯

### Audio Processing Advanced Features
- **VAD Pre-filtering**: è¯­éŸ³æ´»åŠ¨æ£€æµ‹è¿‡æ»¤é™éŸ³æ®µ
- **Audio Compression**: Int16 å‹ç¼©å‡å°‘ä¼ è¾“å¸¦å®½
- **Adaptive Noise Floor**: è‡ªé€‚åº”å™ªå£°åº•éƒ¨è¿½è¸ª
- **SNR Monitoring**: å®æ—¶ä¿¡å™ªæ¯”ç›‘æµ‹ï¼ŒOverlayPanel æ˜¾ç¤ºä¿¡å·è´¨é‡

### Chinese Dialect Support
`server/main.py` çš„ `LANGUAGE_MAP` æ”¯æŒä¸­æ–‡æ–¹è¨€é€‰é¡¹ä¼ é€’ç»™ Qwen3-ASRã€‚

## Key Files for Common Tasks

| Task | Files |
|------|-------|
| Modify hotkey behavior | `VoiceFlow/Sources/Core/HotkeyManager.swift` |
| Change audio processing | `VoiceFlow/Sources/Core/AudioRecorder.swift` |
| Adjust WebSocket protocol | `VoiceFlow/Sources/Core/ASRClient.swift` + `server/main.py` |
| Add UI elements | `VoiceFlow/Sources/UI/StatusBarController.swift` |
| Modify ASR model | `server/mlx_asr.py` |
| Add text post-processing | `server/text_polisher.py` or create new plugin |
| Configure LLM polish | `VoiceFlow/Sources/Core/LLMSettings.swift` + `server/llm_client.py` |
| Add history analysis | `server/history_analyzer.py` + `VoiceFlow/Sources/UI/HistoryAnalysisView.swift` |

## Debugging

### Audio Capture
```
[AudioRecorder] Audio device: MacBook Pro Microphone
[AudioRecorder] Recording started.
```

### WebSocket Connection
Auto-reconnects every 3 seconds on disconnect:
```
[ASRClient] Connected to ws://localhost:9876
[ASRClient] Attempting reconnect...
```

### Hotkey Issues
Verify Accessibility permissions in System Settings â†’ Privacy & Security â†’ Accessibility:
```
[HotkeyManager] FAILED to create event tap! Check permissions.
```

**Important:** Toggle accessibility permission offâ†’on after each rebuild (code signature changes).

### ASR Server
Check Python server logs for transcription errors:
```
[ASRServer] stderr: 2026-02-02 [INFO] ğŸ¤ å¼€å§‹å½•éŸ³
[ASRServer] stderr: 2026-02-02 [INFO] âœ… è½¬å½•å®Œæˆ
```

## Code Guidelines

- Use `NSLog()` for important events (connection status, errors)
- Use `Logger` (os.log) for detailed debug info in HotkeyManager
- All audio processing happens on `sessionQueue` background thread
- UI updates must dispatch to `DispatchQueue.main`
- WebSocket reconnection is automatic - don't manually retry in UI code
- When `language` is set to "auto", pass `None` to MLX model (don't pass the parameter)

## Permissions Required

1. **Microphone Access**: Required for `AudioRecorder` to capture audio
2. **Accessibility Access**: Required for `HotkeyManager` global event monitoring and `TextInjector` text injection

Both are requested automatically on first launch.

## Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `VOICEFLOW_PYTHON` | Python interpreter path | `<project_root>/.venv/bin/python3` |

## Known Issues & Solutions

### WebSocket Connection Race Condition
ASRClient çš„ WebSocket è¿æ¥å¯èƒ½å‡ºç° `NSURLErrorDomain Code=-999 "cancelled"` é”™è¯¯ã€‚åŸå› æ˜¯ `URLSessionWebSocketTask.resume()` åç«‹å³å‘é€ pingï¼Œæ­¤æ—¶æ¡æ‰‹å¯èƒ½å°šæœªå®Œæˆã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼ˆå·²åœ¨ä»£ç ä¸­å®ç°ï¼‰ï¼š
- åœ¨ ping å‰æ·»åŠ  500ms å»¶è¿Ÿç­‰å¾…æ¡æ‰‹å®Œæˆ
- ä½¿ç”¨ `===` èº«ä»½æ£€æŸ¥ç¡®ä¿å¼‚æ­¥å›è°ƒæ“ä½œçš„æ˜¯å½“å‰è¿æ¥
- å–æ¶ˆæ—§çš„é‡è¿ä»»åŠ¡é˜²æ­¢å¹¶å‘å†²çª
- `handleDisconnect()` ä»…åœ¨çŠ¶æ€ä»å·²è¿æ¥å˜ä¸ºæ–­å¼€æ—¶å‘é€é€šçŸ¥

### Plugin System

**æ’ä»¶ä½ç½®ï¼š**
- å†…ç½®æ’ä»¶: `Plugins/` ç›®å½•ï¼ˆéšé¡¹ç›®åˆ†å‘ï¼‰
- ç”¨æˆ·æ’ä»¶: `~/Library/Application Support/VoiceFlow/Plugins/`

**è‡ªåŠ¨å®‰è£…ï¼š** ASR æœåŠ¡å™¨å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨å°† `ChinesePunctuationPlugin` ä»å†…ç½®ç›®å½•å¤åˆ¶åˆ°ç”¨æˆ·ç›®å½•ã€‚

**manifest.json å¿…éœ€å­—æ®µï¼š**
```json
{
  "name": "PluginName",
  "version": "1.0.0",
  "platform": ["python"],
  "entry_point": "plugin.py"
}
```

**æ’ä»¶ç”Ÿå‘½å‘¨æœŸï¼š**
1. æœåŠ¡å™¨å¯åŠ¨æ—¶åŠ è½½æ‰€æœ‰æ’ä»¶ (`plugin_loader.py`)
2. æ¯ä¸ªæ’ä»¶å®ç° `process(text)` æ–¹æ³•å¤„ç†è½¬å½•æ–‡æœ¬
3. æ’ä»¶æŒ‰é¡ºåºæ‰§è¡Œï¼Œå‰ä¸€ä¸ªæ’ä»¶çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªçš„è¾“å…¥
