#!/usr/bin/env python3
"""VoiceFlow ASR WebSocket Server using MLX Qwen3-ASR with Apple Silicon acceleration."""

import asyncio
import json
import logging
import time
from pathlib import Path

import numpy as np
import websockets
from mlx_asr import MLXQwen3ASR
from text_polisher import TextPolisher

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

HOST = "localhost"
PORT = 9876

model: MLXQwen3ASR = None
polisher: TextPolisher = None
config = {}


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    global config
    config_path = Path(__file__).parent.parent / "config.json"

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            logger.info(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {config}")
    except FileNotFoundError:
        config = {"model_id": "mlx-community/Qwen3-ASR-0.6B-8bit", "language": "Chinese"}
        logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {config}")
    except Exception as e:
        config = {"model_id": "mlx-community/Qwen3-ASR-0.6B-8bit", "language": "Chinese"}
        logger.error(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

    return config


def load_model():
    """åŠ è½½ MLX Qwen3-ASR æ¨¡å‹"""
    global model

    model_id = config.get("model_id", "mlx-community/Qwen3-ASR-0.6B-8bit")
    logger.info(f"æ­£åœ¨åŠ è½½MLXæ¨¡å‹: {model_id}")

    try:
        model = MLXQwen3ASR(model_id=model_id)
        logger.info(f"âœ… MLXæ¨¡å‹åŠ è½½æˆåŠŸ: {model_id}")
        logger.info("ğŸš€ ä½¿ç”¨Apple Silicon GPUåŠ é€Ÿ")
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise


def warmup_model():
    """Warm up the model with a short silent audio segment."""
    global model, polisher
    if model is None:
        raise RuntimeError("Model not loaded. Call load_model() first.")

    logger.info("Warming up model with silent audio...")
    silent_audio = np.zeros(16000, dtype=np.float32)

    try:
        language = config.get("language", "Chinese")
        _ = model.transcribe(audio=(silent_audio, 16000), language=language)
        logger.info("âœ… Model warmup completed.")
    except Exception as e:
        logger.warning(f"âš ï¸ Warmup failed: {e}")

    logger.info("Initializing text polisher...")
    polisher = TextPolisher()
    logger.info("âœ… Text polisher initialized.")


async def handle_client(websocket):
    """å¤„ç†å®¢æˆ·ç«¯è¿æ¥"""
    logger.info("å®¢æˆ·ç«¯å·²è¿æ¥")
    audio_chunks: list[bytes] = []
    recording = False
    enable_polish = False

    try:
        async for message in websocket:
            if isinstance(message, str):
                data = json.loads(message)
                msg_type = data.get("type")

                if msg_type == "start":
                    enable_polish = data.get("enable_polish") == "true"
                    logger.info(f"ğŸ¤ å¼€å§‹å½•éŸ³. Polish enabled: {enable_polish}")
                    audio_chunks.clear()
                    recording = True

                elif msg_type == "stop":
                    logger.info("â¹ï¸ åœæ­¢å½•éŸ³ï¼Œæ­£åœ¨å¤„ç†éŸ³é¢‘...")
                    recording = False

                    if not audio_chunks:
                        await websocket.send(json.dumps({"type": "final", "text": ""}))
                        continue

                    raw = b"".join(audio_chunks)
                    samples = np.frombuffer(raw, dtype=np.float32)
                    duration = len(samples) / 16000
                    logger.info(f"ğŸ“Š éŸ³é¢‘: {len(samples)} é‡‡æ ·ç‚¹ ({duration:.1f}s)")

                    language = config.get("language", "Chinese")
                    t0 = time.perf_counter()
                    result = model.transcribe(audio=(samples, 16000), language=language)
                    elapsed = time.perf_counter() - t0

                    # æå–æ–‡æœ¬
                    if isinstance(result, str):
                        original_text = result
                    elif isinstance(result, list) and len(result) > 0:
                        original_text = result[0].text if hasattr(result[0], 'text') else str(result[0])
                    elif hasattr(result, 'text'):
                        original_text = result.text
                    else:
                        original_text = str(result)

                    # Polish the transcribed text only if enabled
                    if enable_polish:
                        polished_text = polisher.polish(original_text)
                        logger.info(f"âœ… è½¬å½•å®Œæˆ ({elapsed:.2f}s): {original_text}")
                        logger.info(f"âœ¨ æ¶¦è‰²åæ–‡æœ¬: {polished_text}")
                    else:
                        polished_text = original_text
                        logger.info(f"âœ… è½¬å½•å®Œæˆ ({elapsed:.2f}s): {original_text} (polish disabled)")

                    await websocket.send(json.dumps({
                        "type": "final",
                        "text": polished_text,
                        "original_text": original_text
                    }))

            elif isinstance(message, bytes) and recording:
                audio_chunks.append(message)

    except websockets.exceptions.ConnectionClosed:
        logger.info("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
    except Exception as e:
        logger.error(f"âŒ é”™è¯¯: {e}", exc_info=True)


async def main():
    load_config()
    load_model()
    warmup_model()

    model_id = config.get("model_id", "mlx-community/Qwen3-ASR-0.6B-8bit")
    logger.info(f"ğŸš€ WebSocket æœåŠ¡å™¨å¯åŠ¨äº ws://{HOST}:{PORT}")
    logger.info(f"ğŸ“Š å½“å‰æ¨¡å‹: {model_id}")
    logger.info("âœ… MLXåŸç”ŸApple SiliconåŠ é€Ÿå·²å¯ç”¨")

    async with websockets.serve(handle_client, HOST, PORT):
        await asyncio.Future()


if __name__ == "__main__":
    asyncio.run(main())
