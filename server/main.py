#!/usr/bin/env python3
"""VoiceFlow ASR WebSocket Server using MLX Qwen3-ASR with Apple Silicon acceleration."""

import asyncio
import json
import logging
import shutil
import time
from pathlib import Path

import numpy as np
import websockets
from mlx_asr import MLXQwen3ASR
from text_polisher import TextPolisher, TimestampAwarePunctuator
from scene_polisher import ScenePolisher
from llm_client import LLMClient, LLMConfig, init_llm_client, get_llm_client, shutdown_llm_client
from llm_polisher import LLMPolisher, init_llm_polisher, get_llm_polisher, DEFAULT_POLISH_PROMPTS
from prompt_config import get_prompt_config
from history_analyzer import HistoryAnalyzer, init_history_analyzer, get_history_analyzer

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

HOST = "localhost"
PORT = 9876

# æ¨¡å‹ç¼“å­˜ï¼šmodel_id -> MLXQwen3ASR å®ä¾‹
models: dict[str, MLXQwen3ASR] = {}
current_model_id: str = None
polisher: TextPolisher = None
scene_polisher: ScenePolisher = None
llm_polisher: LLMPolisher = None
config = {}

# æ¨¡å‹è®¿é—®é”ï¼Œé˜²æ­¢å¹¶å‘è½¬å½•å¯¼è‡´ MLX å´©æºƒ
import threading
model_lock = threading.Lock()

# åå°ä»»åŠ¡é›†åˆï¼Œé˜²æ­¢è¢« GC å›æ”¶
background_tasks: set = set()

# Plugin system
plugins: list = []

# ç”¨æˆ·æ’ä»¶ç›®å½•
USER_PLUGINS_DIR = Path.home() / "Library" / "Application Support" / "VoiceFlow" / "Plugins"

# å†…ç½®æ’ä»¶åˆ—è¡¨ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„ Plugins/ ç›®å½•ï¼‰
BUNDLED_PLUGINS = [
    "ChinesePunctuationPlugin",
]


def install_bundled_plugins():
    """å°†å†…ç½®æ’ä»¶å®‰è£…åˆ°ç”¨æˆ·æ’ä»¶ç›®å½•ï¼ˆé¦–æ¬¡è¿è¡Œæˆ–æ›´æ–°æ—¶ï¼‰"""
    # è·å–é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ Plugins ç›®å½•
    server_dir = Path(__file__).parent
    project_root = server_dir.parent
    bundled_plugins_dir = project_root / "Plugins"

    if not bundled_plugins_dir.exists():
        logger.warning(f"âš ï¸ å†…ç½®æ’ä»¶ç›®å½•ä¸å­˜åœ¨: {bundled_plugins_dir}")
        return

    # ç¡®ä¿ç”¨æˆ·æ’ä»¶ç›®å½•å­˜åœ¨
    USER_PLUGINS_DIR.mkdir(parents=True, exist_ok=True)

    for plugin_name in BUNDLED_PLUGINS:
        src_dir = bundled_plugins_dir / plugin_name
        dst_dir = USER_PLUGINS_DIR / plugin_name

        if not src_dir.exists():
            logger.warning(f"âš ï¸ å†…ç½®æ’ä»¶ä¸å­˜åœ¨: {plugin_name}")
            continue

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®‰è£…æˆ–æ›´æ–°
        src_manifest = src_dir / "manifest.json"
        dst_manifest = dst_dir / "manifest.json"

        should_install = False

        if not dst_dir.exists():
            should_install = True
            logger.info(f"ğŸ“¦ é¦–æ¬¡å®‰è£…æ’ä»¶: {plugin_name}")
        elif src_manifest.exists() and dst_manifest.exists():
            # æ¯”è¾ƒç‰ˆæœ¬å·å†³å®šæ˜¯å¦æ›´æ–°
            try:
                with open(src_manifest, 'r', encoding='utf-8') as f:
                    src_version = json.load(f).get("version", "0.0.0")
                with open(dst_manifest, 'r', encoding='utf-8') as f:
                    dst_version = json.load(f).get("version", "0.0.0")

                if src_version > dst_version:
                    should_install = True
                    logger.info(f"ğŸ“¦ æ›´æ–°æ’ä»¶: {plugin_name} ({dst_version} -> {src_version})")
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•æ¯”è¾ƒæ’ä»¶ç‰ˆæœ¬: {e}")

        if should_install:
            try:
                # åˆ é™¤æ—§ç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if dst_dir.exists():
                    shutil.rmtree(dst_dir)

                # å¤åˆ¶æ’ä»¶ç›®å½•
                shutil.copytree(src_dir, dst_dir)
                logger.info(f"âœ… æ’ä»¶å·²å®‰è£…: {plugin_name} -> {dst_dir}")
            except Exception as e:
                logger.error(f"âŒ æ’ä»¶å®‰è£…å¤±è´¥ {plugin_name}: {e}")


def register_plugin(plugin_func):
    """Register a plugin function to process transcription results.

    Plugin function should accept text (str) and return modified text (str).
    """
    plugins.append(plugin_func)
    logger.info(f"Registered plugin: {plugin_func.__name__}")


def run_plugins(text: str) -> str:
    """Run all registered plugins on the transcribed text."""
    result = text
    for plugin in plugins:
        try:
            result = plugin(result)
        except Exception as e:
            logger.error(f"Plugin {plugin.__name__} failed: {e}")
    return result


# è¯­è¨€ä»£ç åˆ° mlx-audio è¯­è¨€åç§°çš„æ˜ å°„
LANGUAGE_MAP = {
    "auto": None,  # None è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
    "zh": "Chinese",
    "en": "English",
    "yue": "Cantonese",
    "ja": "Japanese",
    "ko": "Korean",
    "de": "German",
    "fr": "French",
    "es": "Spanish",
    "pt": "Portuguese",
    "it": "Italian",
    "ru": "Russian",
    "nl": "Dutch",
    "sv": "Swedish",
    "da": "Danish",
    "fi": "Finnish",
    "pl": "Polish",
    "cs": "Czech",
    "el": "Greek",
    "hu": "Hungarian",
    "mk": "Macedonian",
    "ro": "Romanian",
    "ar": "Arabic",
    "id": "Indonesian",
    "th": "Thai",
    "vi": "Vietnamese",
    "tr": "Turkish",
    "hi": "Hindi",
    "ms": "Malay",
    "fil": "Filipino",
    "fa": "Persian",
    # ä¸­å›½æ–¹è¨€ï¼ˆQwen3-ASR ç‹¬å ä¼˜åŠ¿ï¼‰
    "zh-sichuan": "Sichuanese",      # å››å·è¯
    "zh-dongbei": "Northeastern",    # ä¸œåŒ—è¯
    "zh-shanghai": "Shanghainese",   # ä¸Šæµ·è¯
    "zh-minnan": "Hokkien",          # é—½å—è¯­
    "zh-hakka": "Hakka",             # å®¢å®¶è¯
    "zh-wenzhou": "Wenzhou",         # æ¸©å·è¯
    "zh-changsha": "Changsha",       # é•¿æ²™è¯
    "zh-nanchang": "Nanchang",       # å—æ˜Œè¯
}


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    global config
    config_path = Path(__file__).parent.parent / "config.json"

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            logger.info(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {config}")
    except FileNotFoundError:
        config = {"model_id": "mlx-community/Qwen3-ASR-0.6B-8bit", "language": "Chinese"}
        logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {config}")
    except Exception as e:
        config = {"model_id": "mlx-community/Qwen3-ASR-0.6B-8bit", "language": "Chinese"}
        logger.error(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

    return config


def load_model(model_id: str = None):
    """åŠ è½½ MLX Qwen3-ASR æ¨¡å‹ï¼ˆæ”¯æŒåŠ¨æ€åˆ‡æ¢ï¼‰"""
    global models, current_model_id

    if model_id is None:
        model_id = config.get("model_id", "mlx-community/Qwen3-ASR-0.6B-8bit")

    # å¦‚æœå·²ç»åŠ è½½è¿‡è¯¥æ¨¡å‹ï¼Œç›´æ¥è¿”å›
    if model_id in models:
        current_model_id = model_id
        logger.info(f"âœ… ä½¿ç”¨å·²ç¼“å­˜æ¨¡å‹: {model_id}")
        return models[model_id]

    logger.info(f"æ­£åœ¨åŠ è½½MLXæ¨¡å‹: {model_id}")

    try:
        model = MLXQwen3ASR(model_id=model_id)
        models[model_id] = model
        current_model_id = model_id
        logger.info(f"âœ… MLXæ¨¡å‹åŠ è½½æˆåŠŸ: {model_id}")
        logger.info("ğŸš€ ä½¿ç”¨Apple Silicon GPUåŠ é€Ÿ")
        return model
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise


def get_model(model_id: str = None) -> MLXQwen3ASR:
    """è·å–æ¨¡å‹å®ä¾‹ï¼Œå¦‚æœæœªåŠ è½½åˆ™è‡ªåŠ¨åŠ è½½"""
    if model_id is None:
        model_id = current_model_id or config.get("model_id", "mlx-community/Qwen3-ASR-0.6B-8bit")

    if model_id not in models:
        return load_model(model_id)

    return models[model_id]


# ============== VAD æµå¼è½¬å½•ç›¸å…³å‡½æ•° ==============

def calculate_rms(samples: np.ndarray) -> float:
    """è®¡ç®—éŸ³é¢‘ç‰‡æ®µçš„ RMS èƒ½é‡"""
    if len(samples) == 0:
        return 0.0
    return float(np.sqrt(np.mean(samples ** 2)))


def is_silence(samples: np.ndarray, threshold: float = 0.01) -> bool:
    """åˆ¤æ–­éŸ³é¢‘ç‰‡æ®µæ˜¯å¦ä¸ºé™éŸ³"""
    return calculate_rms(samples) < threshold


def extract_text(result) -> str:
    """ä»æ¨¡å‹ç»“æœä¸­æå–æ–‡æœ¬"""
    if isinstance(result, str):
        return result
    elif isinstance(result, list) and len(result) > 0:
        return result[0].text if hasattr(result[0], 'text') else str(result[0])
    elif hasattr(result, 'text'):
        return result.text
    else:
        return str(result)


async def vad_streaming_transcribe(
    websocket,
    audio_chunks: list,
    model,
    language,
    silence_threshold: float = 0.01,
    silence_duration_ms: int = 300,
    check_interval_ms: int = 100
):
    """
    åŸºäº VAD çš„æµå¼è½¬å½•ï¼šä»…åœ¨æ£€æµ‹åˆ°åœé¡¿æ—¶è§¦å‘è½¬å½•

    Args:
        websocket: WebSocket è¿æ¥
        audio_chunks: éŸ³é¢‘æ•°æ®å—åˆ—è¡¨
        model: ASR æ¨¡å‹å®ä¾‹
        language: è¯­è¨€è®¾ç½®
        silence_threshold: é™éŸ³é˜ˆå€¼ (RMS)ï¼Œé™ä½æ›´æ•æ„Ÿ
        silence_duration_ms: éœ€è¦æŒç»­é™éŸ³å¤šä¹…æ‰è§¦å‘ (æ¯«ç§’)
        check_interval_ms: æ£€æŸ¥é—´éš” (æ¯«ç§’)
    """
    silence_frames = 0
    frames_needed = silence_duration_ms // check_interval_ms
    last_transcribed_length = 0
    last_text = ""
    is_transcribing = False  # é˜²æ­¢å¹¶å‘è½¬å½•

    logger.info(f"ğŸ™ï¸ VAD æµå¼è½¬å½•å·²å¯åŠ¨ (threshold={silence_threshold}, pause={silence_duration_ms}ms)")

    async def do_transcribe(samples, trigger_reason: str):
        """æ‰§è¡Œè½¬å½•å¹¶å‘é€ç»“æœ"""
        nonlocal last_text, last_transcribed_length, is_transcribing

        if is_transcribing:
            return  # é¿å…å¹¶å‘è½¬å½•

        is_transcribing = True
        try:
            def transcribe_with_lock():
                with model_lock:
                    return model.transcribe((samples, 16000), language)

            result = await asyncio.to_thread(transcribe_with_lock)
            text = extract_text(result)

            # åªåœ¨æ–‡æœ¬å˜åŒ–æ—¶å‘é€
            if text and text != last_text:
                last_text = text
                last_transcribed_length = len(samples)
                await websocket.send(json.dumps({
                    "type": "partial",
                    "text": text
                }))
                logger.info(f"ğŸ“ Partial ({trigger_reason}): {text}")

        except Exception as e:
            logger.warning(f"âš ï¸ è½¬å½•å¤±è´¥ ({trigger_reason}): {e}")
        finally:
            is_transcribing = False

    try:
        while True:
            await asyncio.sleep(check_interval_ms / 1000)

            if not audio_chunks:
                continue

            # è·å–å½“å‰æ‰€æœ‰éŸ³é¢‘
            raw = b"".join(audio_chunks)
            samples = np.frombuffer(raw, dtype=np.float32)

            if len(samples) < 1600:  # è‡³å°‘ 100ms (16000Hz * 0.1s)
                continue

            # æ£€æŸ¥æœ€è¿‘ 100ms çš„éŸ³é¢‘èƒ½é‡
            recent_samples = samples[-1600:]

            if is_silence(recent_samples, silence_threshold):
                silence_frames += 1
            else:
                silence_frames = 0

            # è§¦å‘æ¡ä»¶ï¼šæ£€æµ‹åˆ°åœé¡¿ï¼Œä¸”æœ‰æ–°éŸ³é¢‘
            pause_trigger = silence_frames >= frames_needed and len(samples) > last_transcribed_length

            if pause_trigger:
                await do_transcribe(samples, "pause")
                silence_frames = 0

    except asyncio.CancelledError:
        logger.info("ğŸ›‘ VAD æµå¼è½¬å½•ä»»åŠ¡å·²å–æ¶ˆ")
        raise


def warmup_model():
    """Warm up the model with a short silent audio segment."""
    global polisher, scene_polisher, llm_polisher
    model = get_model()
    if model is None:
        raise RuntimeError("Model not loaded. Call load_model() first.")

    logger.info("Warming up model with silent audio...")
    silent_audio = np.zeros(16000, dtype=np.float32)

    try:
        language = config.get("language", "Chinese")
        _ = model.transcribe(audio=(silent_audio, 16000), language=language)
        logger.info("âœ… Model warmup completed.")
    except Exception as e:
        logger.warning(f"âš ï¸ Warmup failed: {e}")

    logger.info("Initializing text polisher...")
    polisher = TextPolisher()
    scene_polisher = ScenePolisher(polisher)
    logger.info("âœ… Text polisher and scene polisher initialized.")

    # Initialize LLM components (with default config, will be updated by client)
    logger.info("Initializing LLM components...")
    init_llm_client()
    llm_polisher = init_llm_polisher(base_polisher=polisher)
    init_history_analyzer()
    logger.info("âœ… LLM polisher and history analyzer initialized.")


async def handle_client(websocket):
    """å¤„ç†å®¢æˆ·ç«¯è¿æ¥"""
    logger.info("å®¢æˆ·ç«¯å·²è¿æ¥")
    audio_chunks: list[bytes] = []
    recording = False
    enable_polish = False
    use_llm_polish = False  # LLM æ¶¦è‰²å¼€å…³
    use_timestamps = False  # æ—¶é—´æˆ³æ™ºèƒ½æ–­å¥å¼€å…³
    session_model_id = None
    session_language = None
    session_scene = None  # åœºæ™¯ä¿¡æ¯
    transcription_task: asyncio.Task = None

    try:
        async for message in websocket:
            if isinstance(message, str):
                data = json.loads(message)
                msg_type = data.get("type")

                if msg_type == "config_llm":
                    # é…ç½® LLM è¿æ¥å‚æ•°
                    llm_config = LLMConfig.from_dict(data.get("config", {}))
                    llm_client = get_llm_client()
                    if llm_client:
                        llm_client.update_config(llm_config)
                        logger.info(f"ğŸ”§ LLM é…ç½®å·²æ›´æ–°: model={llm_config.model}, url={llm_config.api_url}")
                        await websocket.send(json.dumps({
                            "type": "config_llm_ack",
                            "success": True
                        }))
                    else:
                        await websocket.send(json.dumps({
                            "type": "config_llm_ack",
                            "success": False,
                            "error": "LLM client not initialized"
                        }))

                elif msg_type == "test_llm_connection":
                    # æµ‹è¯• LLM è¿æ¥
                    llm_client = get_llm_client()
                    if llm_client:
                        success, latency = await llm_client.health_check()
                        await websocket.send(json.dumps({
                            "type": "test_llm_connection_result",
                            "success": success,
                            "latency_ms": latency
                        }))
                    else:
                        await websocket.send(json.dumps({
                            "type": "test_llm_connection_result",
                            "success": False,
                            "error": "LLM client not initialized"
                        }))

                elif msg_type == "analyze_history":
                    # åˆ†æå½•éŸ³å†å²
                    entries = data.get("entries", [])
                    app_name = data.get("app_name", "Unknown")
                    existing_terms = data.get("existing_terms", [])

                    analyzer = get_history_analyzer()
                    if analyzer:
                        result = await analyzer.analyze_app_history(entries, app_name, existing_terms)
                        await websocket.send(json.dumps({
                            "type": "analysis_result",
                            "result": result
                        }))
                    else:
                        await websocket.send(json.dumps({
                            "type": "analysis_result",
                            "error": "History analyzer not initialized"
                        }))

                elif msg_type == "get_default_prompts":
                    # è·å–é»˜è®¤æç¤ºè¯
                    await websocket.send(json.dumps({
                        "type": "default_prompts",
                        "prompts": DEFAULT_POLISH_PROMPTS
                    }))
                    logger.info("ğŸ“¤ å·²å‘é€é»˜è®¤æç¤ºè¯")

                elif msg_type == "get_custom_prompts":
                    # è·å–ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯
                    prompt_config = get_prompt_config()
                    await websocket.send(json.dumps({
                        "type": "custom_prompts",
                        "prompts": prompt_config.get_all_user_prompts()
                    }))
                    logger.info("ğŸ“¤ å·²å‘é€ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯")

                elif msg_type == "save_custom_prompt":
                    # ä¿å­˜æˆ–é‡ç½®ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯
                    scene_type = data.get("scene_type", "")
                    prompt = data.get("prompt")  # None è¡¨ç¤ºé‡ç½®ä¸ºé»˜è®¤

                    prompt_config = get_prompt_config()
                    try:
                        if prompt is None:
                            # é‡ç½®ä¸ºé»˜è®¤
                            prompt_config.reset_prompt(scene_type)
                            await websocket.send(json.dumps({
                                "type": "save_custom_prompt_ack",
                                "success": True,
                                "scene_type": scene_type,
                                "action": "reset"
                            }))
                            logger.info(f"ğŸ”„ å·²é‡ç½®åœºæ™¯ '{scene_type}' ä¸ºé»˜è®¤æç¤ºè¯")
                        else:
                            # ä¿å­˜è‡ªå®šä¹‰
                            prompt_config.set_prompt(scene_type, prompt)
                            await websocket.send(json.dumps({
                                "type": "save_custom_prompt_ack",
                                "success": True,
                                "scene_type": scene_type,
                                "action": "save"
                            }))
                            logger.info(f"ğŸ’¾ å·²ä¿å­˜åœºæ™¯ '{scene_type}' çš„è‡ªå®šä¹‰æç¤ºè¯")
                    except Exception as e:
                        await websocket.send(json.dumps({
                            "type": "save_custom_prompt_ack",
                            "success": False,
                            "scene_type": scene_type,
                            "error": str(e)
                        }))
                        logger.error(f"âŒ ä¿å­˜æç¤ºè¯å¤±è´¥: {e}")

                elif msg_type == "start":
                    enable_polish = data.get("enable_polish") == "true"
                    use_llm_polish = data.get("use_llm_polish", False)  # æ–°å¢ LLM æ¶¦è‰²å¼€å…³
                    use_timestamps = data.get("use_timestamps", False)  # æ–°å¢æ—¶é—´æˆ³æ™ºèƒ½æ–­å¥å¼€å…³
                    session_model_id = data.get("model_id")
                    lang_code = data.get("language", "auto")
                    session_language = LANGUAGE_MAP.get(lang_code, None)
                    session_scene = data.get("scene", {})  # è§£æåœºæ™¯ä¿¡æ¯
                    active_app = data.get("active_app", {})  # è§£ææ´»è·ƒåº”ç”¨ä¿¡æ¯

                    # å°† active_app ä¿¡æ¯åˆå¹¶åˆ° session_scene
                    if active_app:
                        session_scene["active_app"] = active_app

                    logger.info(f"ğŸ¤ å¼€å§‹å½•éŸ³. Polish: {enable_polish}, LLM: {use_llm_polish}, Timestamps: {use_timestamps}, Model: {session_model_id}, Language: {lang_code} -> {session_language}, Scene: {session_scene.get('type', 'auto')}, App: {active_app.get('name', 'unknown')}")

                    # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
                    if session_model_id:
                        get_model(session_model_id)

                    audio_chunks.clear()
                    recording = True

                    # å¯åŠ¨ VAD æµå¼è½¬å½•ä»»åŠ¡
                    transcription_task = asyncio.create_task(
                        vad_streaming_transcribe(
                            websocket,
                            audio_chunks,
                            get_model(session_model_id),
                            session_language
                        )
                    )

                elif msg_type == "stop":
                    logger.info("â¹ï¸ åœæ­¢å½•éŸ³ï¼Œæ­£åœ¨å¤„ç†éŸ³é¢‘...")
                    recording = False

                    # å–æ¶ˆ VAD è½¬å½•ä»»åŠ¡
                    if transcription_task:
                        transcription_task.cancel()
                        try:
                            await transcription_task
                        except asyncio.CancelledError:
                            pass
                        transcription_task = None

                    if not audio_chunks:
                        await websocket.send(json.dumps({"type": "final", "text": "", "polish_method": "none"}))
                        continue

                    raw = b"".join(audio_chunks)
                    samples = np.frombuffer(raw, dtype=np.float32)
                    duration = len(samples) / 16000
                    logger.info(f"ğŸ“Š éŸ³é¢‘: {len(samples)} é‡‡æ ·ç‚¹ ({duration:.1f}s)")

                    # ä½¿ç”¨ä¼šè¯æŒ‡å®šçš„æ¨¡å‹å’Œè¯­è¨€
                    model = get_model(session_model_id)
                    language = session_language  # None è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹

                    # ASR è½¬å½•ï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
                    t0 = time.perf_counter()
                    try:
                        # ä½¿ç”¨é”ä¿æŠ¤æ¨¡å‹è®¿é—®ï¼Œé˜²æ­¢å¹¶å‘å´©æºƒ
                        if use_timestamps:
                            # ä½¿ç”¨æ—¶é—´æˆ³æ¨¡å¼ï¼ˆä¸¤é˜¶æ®µå¤„ç†ï¼‰
                            def transcribe_with_timestamps_lock():
                                with model_lock:
                                    return model.transcribe_with_timestamps(
                                        audio=(samples, 16000),
                                        language=language
                                    )

                            result = await asyncio.wait_for(
                                asyncio.to_thread(transcribe_with_timestamps_lock),
                                timeout=60.0  # æ—¶é—´æˆ³æ¨¡å¼éœ€è¦æ›´é•¿è¶…æ—¶ï¼ˆä¸¤ä¸ªæ¨¡å‹ï¼‰
                            )
                            # result æ˜¯å­—å…¸: {"text": "...", "words": [...]}
                        else:
                            # ä½¿ç”¨æ™®é€šæ¨¡å¼
                            def transcribe_with_lock():
                                with model_lock:
                                    return model.transcribe(audio=(samples, 16000), language=language)

                            result = await asyncio.wait_for(
                                asyncio.to_thread(transcribe_with_lock),
                                timeout=30.0
                            )

                    except asyncio.TimeoutError:
                        timeout_msg = "60s" if use_timestamps else "30s"
                        logger.error(f"âŒ ASR è½¬å½•è¶…æ—¶ ({timeout_msg})")
                        await websocket.send(json.dumps({
                            "type": "final",
                            "text": "",
                            "original_text": "",
                            "polish_method": "none"
                        }))
                        continue

                    elapsed = time.perf_counter() - t0

                    # æå–æ–‡æœ¬å¹¶å¤„ç†æ—¶é—´æˆ³æ–­å¥
                    if use_timestamps and isinstance(result, dict):
                        # æ—¶é—´æˆ³æ¨¡å¼ï¼šå…ˆç”¨æ—¶é—´æˆ³æ–­å¥
                        words = result.get("words", [])
                        original_text = result.get("text", "")

                        if words:
                            # ä½¿ç”¨ TimestampAwarePunctuator æ™ºèƒ½æ–­å¥
                            punctuator = TimestampAwarePunctuator()
                            original_text = punctuator.punctuate(words)
                            logger.info(f"âœ… æ—¶é—´æˆ³æ–­å¥å®Œæˆ ({elapsed:.2f}s, {len(words)} è¯): {original_text[:50]}...")
                        else:
                            logger.warning("âš ï¸ æ—¶é—´æˆ³å¯¹é½å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬")
                    else:
                        # æ™®é€šæ¨¡å¼ï¼šæå–æ–‡æœ¬
                        if isinstance(result, str):
                            original_text = result
                        elif isinstance(result, list) and len(result) > 0:
                            original_text = result[0].text if hasattr(result[0], 'text') else str(result[0])
                        elif hasattr(result, 'text'):
                            original_text = result.text
                        else:
                            original_text = str(result)

                        logger.info(f"âœ… è½¬å½•å®Œæˆ ({elapsed:.2f}s): {original_text}")

                    # ä¸¤æ­¥å“åº”ç­–ç•¥
                    if enable_polish:
                        # ç¬¬ä¸€æ­¥ï¼šç«‹å³ç”¨è§„åˆ™æ¶¦è‰²è¿”å› (å¿«é€Ÿå“åº”)
                        rule_polished_text = scene_polisher.polish(original_text, session_scene)
                        rule_polished_text = run_plugins(rule_polished_text)

                        await websocket.send(json.dumps({
                            "type": "final",
                            "text": rule_polished_text,
                            "original_text": original_text,
                            "polish_method": "rules"
                        }))
                        logger.info(f"âš¡ å¿«é€Ÿå“åº” (rules): {rule_polished_text}")

                        # ç¬¬äºŒæ­¥ï¼šåå° LLM æ¶¦è‰²ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        llm_pol = get_llm_polisher()
                        logger.info(f"ğŸ” LLM æ¡ä»¶æ£€æŸ¥: llm_pol={llm_pol is not None}, use_llm_polish={use_llm_polish}")
                        if llm_pol and use_llm_polish:
                            async def llm_polish_background():
                                try:
                                    logger.info("ğŸš€ åå° LLM æ¶¦è‰²ä»»åŠ¡å¼€å§‹...")
                                    polished_text, polish_method = await llm_pol.polish_async(
                                        original_text, session_scene, use_llm=True
                                    )
                                    logger.info(f"ğŸ“ LLM æ¶¦è‰²è¿”å›: method={polish_method}")
                                    if polish_method == "llm":
                                        # LLM æ¶¦è‰²æˆåŠŸï¼Œå‘é€æ›´æ–°
                                        polished_text = run_plugins(polished_text)
                                        await websocket.send(json.dumps({
                                            "type": "polish_update",
                                            "text": polished_text
                                        }))
                                        logger.info(f"âœ¨ LLM æ¶¦è‰²å®Œæˆ: {polished_text}")
                                    else:
                                        logger.info(f"â„¹ï¸ LLM æœªç”Ÿæ•ˆï¼Œä½¿ç”¨ {polish_method} æ–¹æ³•")
                                except Exception as e:
                                    logger.warning(f"âš ï¸ åå° LLM æ¶¦è‰²å¤±è´¥: {e}", exc_info=True)

                            # å¯åŠ¨åå°ä»»åŠ¡å¹¶ä¿å­˜å¼•ç”¨é˜²æ­¢ GC å›æ”¶
                            task = asyncio.create_task(llm_polish_background())
                            background_tasks.add(task)
                            task.add_done_callback(background_tasks.discard)
                    else:
                        # ä¸å¯ç”¨æ¶¦è‰²ï¼Œç›´æ¥è¿”å›åŸæ–‡
                        polished_text = run_plugins(original_text)
                        await websocket.send(json.dumps({
                            "type": "final",
                            "text": polished_text,
                            "original_text": original_text,
                            "polish_method": "none"
                        }))

            elif isinstance(message, bytes) and recording:
                # è§£ç éŸ³é¢‘æ•°æ®ï¼ˆæ”¯æŒæ ¼å¼æ ‡è¯†ï¼‰
                if len(message) > 1:
                    format_id = message[0]

                    if format_id == 0x01:
                        # Float32 æ ¼å¼ï¼šè·³è¿‡æ ¼å¼æ ‡è¯†å­—èŠ‚
                        audio_chunks.append(message[1:])
                    elif format_id == 0x02:
                        # Int16 æ ¼å¼ï¼šè½¬æ¢ä¸º Float32
                        audio_data = message[1:]
                        samples = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32767.0
                        audio_chunks.append(samples.tobytes())
                    else:
                        # æ—§æ ¼å¼ï¼ˆæ— æ ‡è¯†ï¼Œæ•´ä¸ª message ç›´æ¥æ˜¯ Float32 æ•°æ®ï¼‰
                        # æ³¨æ„ï¼šä¸è¦å‰¥ç¦»ç¬¬ä¸€ä¸ªå­—èŠ‚ï¼Œå®ƒæ˜¯éŸ³é¢‘æ•°æ®çš„ä¸€éƒ¨åˆ†
                        audio_chunks.append(message)
                else:
                    # ç©ºæ•°æ®æˆ–å•å­—èŠ‚ï¼Œå¿½ç•¥
                    pass

    except websockets.exceptions.ConnectionClosed:
        logger.info("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
    except Exception as e:
        logger.error(f"âŒ é”™è¯¯: {e}", exc_info=True)


async def main():
    load_config()
    install_bundled_plugins()  # å®‰è£…å†…ç½®æ’ä»¶åˆ°ç”¨æˆ·ç›®å½•
    load_model()
    warmup_model()

    model_id = config.get("model_id", "mlx-community/Qwen3-ASR-0.6B-8bit")
    logger.info(f"ğŸš€ WebSocket æœåŠ¡å™¨å¯åŠ¨äº ws://{HOST}:{PORT}")
    logger.info(f"ğŸ“Š å½“å‰æ¨¡å‹: {model_id}")
    logger.info("âœ… MLXåŸç”ŸApple SiliconåŠ é€Ÿå·²å¯ç”¨")

    async with websockets.serve(handle_client, HOST, PORT):
        await asyncio.Future()


if __name__ == "__main__":
    asyncio.run(main())
